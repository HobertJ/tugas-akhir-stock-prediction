{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6052757e762c48c49b7f2755f5b2cb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b74ee11a91f54e26a42c086aa89e120a",
              "IPY_MODEL_3d506da141bd4151b42aedf9086893cb",
              "IPY_MODEL_43fa1d0120bf4c3e8d08d8e5ddd660fc"
            ],
            "layout": "IPY_MODEL_59a1253b811a4fc38261a8956def4f36"
          }
        },
        "b74ee11a91f54e26a42c086aa89e120a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a86994a2e124f119ce16379369677ab",
            "placeholder": "​",
            "style": "IPY_MODEL_4e493e6f893b45718b4a6e07a8b10ed1",
            "value": "Processing FinBERT: BBRI News: "
          }
        },
        "3d506da141bd4151b42aedf9086893cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14fb8c6bb2d041b69fe54f2d9f285805",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61d433c541264a0ab4850b51f6210c4e",
            "value": 0
          }
        },
        "43fa1d0120bf4c3e8d08d8e5ddd660fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97705bc158f245f2a3e651ad79008cd9",
            "placeholder": "​",
            "style": "IPY_MODEL_9b33fa16fa2e4c3d9528363aaea9edad",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "59a1253b811a4fc38261a8956def4f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a86994a2e124f119ce16379369677ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e493e6f893b45718b4a6e07a8b10ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14fb8c6bb2d041b69fe54f2d9f285805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "61d433c541264a0ab4850b51f6210c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97705bc158f245f2a3e651ad79008cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b33fa16fa2e4c3d9528363aaea9edad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This notebook contain the process of converting news content and news headline from text into embedding vector. The process leverage the *transformer* and *sentence_transformer* library from huggingface. The news that is converted is related to BBRI, BBCA, and BMRI stock.\n",
        "\n",
        "The text from the news article that is converted is:\n",
        "1. News content\n",
        "2. News headline\n",
        "\n",
        "The model that is used to convert the text is:\n",
        "1. FinBERT\n",
        "2. IndoBERT (indobert-base-p2)\n",
        "3. paraphrase-multilingual-mpnet-base-v2\n",
        "4. LazarusNLP (all-indo-e5-small-v4)"
      ],
      "metadata": {
        "id": "_k8sr6yYgDuM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymNgrFBoDcQm",
        "outputId": "e1fd742c-ba70-4ea0-9e41-a9dd7961d0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.56.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "bbri_news = pd.read_csv(\"full_raw_bbri_news.csv\")\n",
        "bbca_news = pd.read_csv(\"full_raw_bbca_news.csv\")\n",
        "bmri_news = pd.read_csv(\"full_raw_bmri_news.csv\")"
      ],
      "metadata": {
        "id": "U6c834qrDnnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FinBERT"
      ],
      "metadata": {
        "id": "wuUF6LQ_DtQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# For a sentiment classification model (like FinBERT)\n",
        "tokenizer_finbert = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model_finbert = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n",
        "\n",
        "# Check if GPU is available and move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUfHYK-pDqlZ",
        "outputId": "7575e13d-9774-4eec-c45e-dffce3a4ba77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_finbert_embedding(text_content, headline, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates FinBERT embeddings and sentiment predictions for text content and headline.\n",
        "\n",
        "    Args:\n",
        "        text_content (str): The main text content.\n",
        "        headline (str): The headline text.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the text content embedding and the headline embedding.\n",
        "    \"\"\"\n",
        "\n",
        "    # Process the steps using batching\n",
        "    texts = [text_content, headline]\n",
        "    # Process text content\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    # Move input tensors to the same device as the model\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "\n",
        "    text_embedding = embeddings[0]\n",
        "    headline_embedding = embeddings[1]\n",
        "\n",
        "    return (text_embedding, headline_embedding)"
      ],
      "metadata": {
        "id": "TsUg_CRGnSwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBRI NEWS"
      ],
      "metadata": {
        "id": "UDU3tPBYD1Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings = []\n",
        "headline_embeddings = []\n",
        "\n",
        "for index, row in tqdm(bbri_news.iterrows(), desc=\"Processing FinBERT: BBRI News\"):\n",
        "    text_content = row['text_content']\n",
        "    headline = row['headline']\n",
        "\n",
        "    (text_embedding, headline_embedding) = generate_finbert_embedding(text_content, headline, model_finbert, tokenizer_finbert)\n",
        "\n",
        "    text_embeddings.append(text_embedding)\n",
        "    headline_embeddings.append(headline_embedding)\n",
        "\n",
        "bbri_news['text_embedding_finbert'] = text_embeddings\n",
        "bbri_news['headline_embedding_finbert'] = headline_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "6052757e762c48c49b7f2755f5b2cb99",
            "b74ee11a91f54e26a42c086aa89e120a",
            "3d506da141bd4151b42aedf9086893cb",
            "43fa1d0120bf4c3e8d08d8e5ddd660fc",
            "59a1253b811a4fc38261a8956def4f36",
            "2a86994a2e124f119ce16379369677ab",
            "4e493e6f893b45718b4a6e07a8b10ed1",
            "14fb8c6bb2d041b69fe54f2d9f285805",
            "61d433c541264a0ab4850b51f6210c4e",
            "97705bc158f245f2a3e651ad79008cd9",
            "9b33fa16fa2e4c3d9528363aaea9edad"
          ]
        },
        "id": "ovViTfFwD3Ne",
        "outputId": "87129eb4-ac5c-472e-816f-3ae67cee78f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing FinBERT: BBRI News: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6052757e762c48c49b7f2755f5b2cb99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "generate_finbert_embedding() missing 2 required positional arguments: 'model' and 'tokenizer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2475108933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mheadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadline_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_finbert_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtext_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: generate_finbert_embedding() missing 2 required positional arguments: 'model' and 'tokenizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBCA NEWS"
      ],
      "metadata": {
        "id": "OnACCHXJFyif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings = []\n",
        "headline_embeddings = []\n",
        "\n",
        "for index, row in tqdm(bbca_news.iterrows(), desc=\"Processing FinBERT: BBCA News\"):\n",
        "    text_content = row['text_content']\n",
        "    headline = row['headline']\n",
        "\n",
        "    (text_embedding, headline_embedding) = generate_finbert_embedding(text_content, headline, model_finbert, tokenizer_finbert)\n",
        "\n",
        "    text_embeddings.append(text_embedding)\n",
        "    headline_embeddings.append(headline_embedding)\n",
        "\n",
        "bbca_news['text_embedding_finbert'] = text_embeddings\n",
        "bbca_news['headline_embedding_finbert'] = headline_embeddings"
      ],
      "metadata": {
        "id": "t7UNRHJDF2LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BMRI NEWS"
      ],
      "metadata": {
        "id": "AhyHQfpRF0Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings = []\n",
        "headline_embeddings = []\n",
        "\n",
        "for index, row in tqdm(bmri_news.iterrows(), desc=\"Processing FinBERT: BMRI News\"):\n",
        "    text_content = row['text_content']\n",
        "    headline = row['headline']\n",
        "\n",
        "    (text_embedding, headline_embedding) = generate_finbert_embedding(text_content, headline, model_finbert, tokenizer_finbert)\n",
        "\n",
        "    text_embeddings.append(text_embedding)\n",
        "    headline_embeddings.append(headline_embedding)\n",
        "\n",
        "bmri_news['text_embedding_finbert'] = text_embeddings\n",
        "bmri_news['headline_embedding_finbert'] = headline_embeddings"
      ],
      "metadata": {
        "id": "EvZ2ox4nFyFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IndoBERT"
      ],
      "metadata": {
        "id": "x7kD-zcrGGf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load the standard IndoBERT model (Phase 2)\n",
        "# For a sentiment-focused model, you could use \"indobenchmark/indobert-base-p1\"\n",
        "model_name = \"indobenchmark/indobert-base-p2\"\n",
        "tokenizer_indobert = AutoTokenizer.from_pretrained(model_name)\n",
        "model_indobert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "AzItQkX3GF3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_indobert_embedding(text_content, headline, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates IndoBERT embeddings and sentiment predictions for text content and headline.\n",
        "\n",
        "    Args:\n",
        "        text_content (str): The main text content.\n",
        "        headline (str): The headline text.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the text content embedding and the headline embedding.\n",
        "    \"\"\"\n",
        "\n",
        "    # Process the steps using batching\n",
        "    texts = [text_content, headline]\n",
        "    # Process text content\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    # Move input tensors to the same device as the model\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "\n",
        "    text_embedding = embeddings[0]\n",
        "    headline_embedding = embeddings[1]\n",
        "\n",
        "    return (text_embedding, headline_embedding)"
      ],
      "metadata": {
        "id": "_vtVSTgSGaWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBRI NEWS"
      ],
      "metadata": {
        "id": "2cRNHzdsHQst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings = []\n",
        "headline_embeddings = []\n",
        "\n",
        "for index, row in tqdm(bbri_news.iterrows(), desc=\"Processing IndoBERT: BBRI News\"):\n",
        "    text_content = row['text_content']\n",
        "    headline = row['headline']\n",
        "\n",
        "    (text_embedding, headline_embedding) = generate_indobert_embedding(text_content, headline, model_indobert, tokenizer_indobert)\n",
        "\n",
        "    text_embeddings.append(text_embedding)\n",
        "    headline_embeddings.append(headline_embedding)\n",
        "\n",
        "bbri_news['text_embedding_finbert'] = text_embeddings\n",
        "bbri_news['headline_embedding_finbert'] = headline_embeddings"
      ],
      "metadata": {
        "id": "ttP6d963HX4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBCA NEWS"
      ],
      "metadata": {
        "id": "XAaamPfuHR4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings = []\n",
        "headline_embeddings = []\n",
        "\n",
        "for index, row in tqdm(bbca_news.iterrows(), desc=\"Processing IndoBERT: BBCA News\"):\n",
        "    text_content = row['text_content']\n",
        "    headline = row['headline']\n",
        "\n",
        "    (text_embedding, headline_embedding) = generate_indobert_embedding(text_content, headline, model_indobert, tokenizer_indobert)\n",
        "\n",
        "    text_embeddings.append(text_embedding)\n",
        "    headline_embeddings.append(headline_embedding)\n",
        "\n",
        "bbca_news['text_embedding_finbert'] = text_embeddings\n",
        "bbca_news['headline_embedding_finbert'] = headline_embeddings"
      ],
      "metadata": {
        "id": "N9BU41wtHYiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BMRI NEWS"
      ],
      "metadata": {
        "id": "Akn4izAWHTev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings = []\n",
        "headline_embeddings = []\n",
        "\n",
        "for index, row in tqdm(bmri_news.iterrows(), desc=\"Processing IndoBERT: BMRI News\"):\n",
        "    text_content = row['text_content']\n",
        "    headline = row['headline']\n",
        "\n",
        "    (text_embedding, headline_embedding) = generate_indobert_embedding(text_content, headline, model_indobert, tokenizer_indobert)\n",
        "\n",
        "    text_embeddings.append(text_embedding)\n",
        "    headline_embeddings.append(headline_embedding)\n",
        "\n",
        "bmri_news['text_embedding_finbert'] = text_embeddings\n",
        "bmri_news['headline_embedding_finbert'] = headline_embeddings"
      ],
      "metadata": {
        "id": "mr6_7jwwHY_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# paraphrase-multilingual-mpnet-base-v2"
      ],
      "metadata": {
        "id": "OJIBqBn9gGMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model_multilingual = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "DnHHTIyL-SfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBRI NEWS"
      ],
      "metadata": {
        "id": "Ng5u3nmF-mXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas(desc=\"Processing multilingual-mpnet: BBRI news content\")\n",
        "bbri_news['text_embedding_multilingual_mpnet'] = bbri_news['text_content'].progress_apply(lambda x: model_multilingual.encode(x))\n",
        "\n",
        "tqdm.pandas(desc=\"Processing multilingual-mpnet: BBRI news headline\")\n",
        "bbri_news['headline_embedding_multilingual_mpnet'] = bbri_news['headline'].progress_apply(lambda x: model_multilingual.encode(x))"
      ],
      "metadata": {
        "id": "Gptdj_Ir-tSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBCA NEWS"
      ],
      "metadata": {
        "id": "ZCFsgHpI-nh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas(desc=\"Processing multilingual-mpnet: BBCA news content\")\n",
        "bbca_news['text_embedding_multilingual_mpnet'] = bbca_news['text_content'].progress_apply(lambda x: model_multilingual.encode(x))\n",
        "\n",
        "tqdm.pandas(desc=\"Processing multilingual-mpnet: BBCA news headline\")\n",
        "bbca_news['headline_embedding_multilingual_mpnet'] = bbca_news['headline'].progress_apply(lambda x: model_multilingual.encode(x))"
      ],
      "metadata": {
        "id": "QESvqt2p-txE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BMRI NEWS"
      ],
      "metadata": {
        "id": "yrlor1r_-rNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas(desc=\"Processing multilingual-mpnet: BMRI news content\")\n",
        "bmri_news['text_embedding_multilingual_mpnet'] = bmri_news['text_content'].progress_apply(lambda x: model_multilingual.encode(x))\n",
        "\n",
        "tqdm.pandas(desc=\"Processing multilingual-mpnet: BMRI news headline\")\n",
        "bmri_news['headline_embedding_multilingual_mpnet'] = bmri_news['headline'].progress_apply(lambda x: model_multilingual.encode(x))"
      ],
      "metadata": {
        "id": "H7-eJGrM-umQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LazarusNLP / all-indo-e5-small-v4"
      ],
      "metadata": {
        "id": "rWQni0BoC-gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model_lazarus = SentenceTransformer('LazarusNLP/all-indo-e5-small-v4')"
      ],
      "metadata": {
        "id": "TDmfKqbXDPaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBRI NEWS"
      ],
      "metadata": {
        "id": "L3hzfCzrDC-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas(desc=\"Processing LazarusNLP: BBRI news content\")\n",
        "bbri_news['text_embedding_lazarus'] = bbri_news['text_content'].progress_apply(lambda x: model_lazarus.encode(x))\n",
        "\n",
        "tqdm.pandas(desc=\"Processing LazarusNLP: BBRI news headline\")\n",
        "bbri_news['headline_embedding_lazarus'] = bbri_news['headline'].progress_apply(lambda x: model_lazarus.encode(x))"
      ],
      "metadata": {
        "id": "XtfY5p_kDNBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBCA NEWS"
      ],
      "metadata": {
        "id": "s3GwC6rxDJf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas(desc=\"Processing LazarusNLP: BBCA news content\")\n",
        "bbca_news['text_embedding_lazarus'] = bbca_news['text_content'].progress_apply(lambda x: model_lazarus.encode(x))\n",
        "\n",
        "tqdm.pandas(desc=\"Processing LazarusNLP: BBCA news headline\")\n",
        "bbca_news['headline_embedding_lazarus'] = bbca_news['headline'].progress_apply(lambda x: model_lazarus.encode(x))"
      ],
      "metadata": {
        "id": "UM5y9IolDNkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BMRI NEWS"
      ],
      "metadata": {
        "id": "a4hVsHRkDK4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas(desc=\"Processing LazarusNLP: BMRI news content\")\n",
        "bmri_news['text_embedding_lazarus'] = bmri_news['text_content'].progress_apply(lambda x: model_lazarus.encode(x))\n",
        "\n",
        "tqdm.pandas(desc=\"Processing LazarusNLP: BMRI news headline\")\n",
        "bmri_news['headline_embedding_lazarus'] = bmri_news['headline'].progress_apply(lambda x: model_lazarus.encode(x))"
      ],
      "metadata": {
        "id": "7BmiWnJaDN_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL RESULT"
      ],
      "metadata": {
        "id": "w9wBjGyYErES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bbri_news.to_csv(\"bbri_news_with_embeddings.csv\", index=False)\n",
        "bbca_news.to_csv(\"bbca_news_with_embeddings.csv\", index=False)\n",
        "bmri_news.to_csv(\"bmri_news_with_embeddings.csv\", index=False)"
      ],
      "metadata": {
        "id": "WuxTUOMZEqpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# this result in the embedding vector for each stock news using the model that has been defined\n",
        "files.download(\"bbri_news_with_embeddings.csv\")\n",
        "files.download(\"bbca_news_with_embeddings.csv\")\n",
        "files.download(\"bmri_news_with_embeddings.csv\")"
      ],
      "metadata": {
        "id": "u1VAGz58FM7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregate the news embedding into daily data"
      ],
      "metadata": {
        "id": "LFJk0TUAkT2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBRI News"
      ],
      "metadata": {
        "id": "gntI9ratkYIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Group by date and aggregate the embedding columns by averaging for BBRI data\n",
        "aggregated_bbri_embeddings = bbri_news.groupby('date').agg(\n",
        "    text_embedding_finbert=('text_embedding_finbert', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_finbert=('headline_embedding_finbert', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_indobert=('text_embedding_indobert', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_indobert=('headline_embedding_indobert', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_multilingual_mpnet=('text_embedding_multilingual_mpnet', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_multilingual_mpnet=('headline_embedding_multilingual_mpnet', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_lazarus=('text_embedding_lazarus', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_lazarus=('headline_embedding_lazarus', lambda x: np.mean(list(x), axis=0))\n",
        ").reset_index()\n",
        "\n",
        "print(aggregated_bbri_embeddings.shape)"
      ],
      "metadata": {
        "id": "ChAavQqTkWNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BBCA News"
      ],
      "metadata": {
        "id": "d_SmvSrIl6qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Group by date and aggregate the embedding columns by averaging for BBCA data\n",
        "aggregated_bbca_embeddings = bbca_news.groupby('date').agg(\n",
        "    text_embedding_finbert=('text_embedding_finbert', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_finbert=('headline_embedding_finbert', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_indobert=('text_embedding_indobert', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_indobert=('headline_embedding_indobert', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_multilingual_mpnet=('text_embedding_multilingual_mpnet', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_multilingual_mpnet=('headline_embedding_multilingual_mpnet', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_lazarus=('text_embedding_lazarus', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_lazarus=('headline_embedding_lazarus', lambda x: np.mean(list(x), axis=0))\n",
        ").reset_index()\n",
        "\n",
        "print(aggregated_bbca_embeddings.shape)"
      ],
      "metadata": {
        "id": "_Vz6MMw9mAkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BMRI News"
      ],
      "metadata": {
        "id": "wmWfedUUl83S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Group by date and aggregate the embedding columns by averaging for BMRI data\n",
        "aggregated_bmri_embeddings = bmri_news.groupby('date').agg(\n",
        "    text_embedding_finbert=('text_embedding_finbert', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_finbert=('headline_embedding_finbert', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_indobert=('text_embedding_indobert', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_indobert=('headline_embedding_indobert', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_multilingual_mpnet=('text_embedding_multilingual_mpnet', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_multilingual_mpnet=('headline_embedding_multilingual_mpnet', lambda x: np.mean(list(x), axis=0)),\n",
        "\n",
        "    text_embedding_lazarus=('text_embedding_lazarus', lambda x: np.mean(list(x), axis=0)),\n",
        "    headline_embedding_lazarus=('headline_embedding_lazarus', lambda x: np.mean(list(x), axis=0))\n",
        ").reset_index()\n",
        "\n",
        "print(aggregated_bmri_embeddings.shape)"
      ],
      "metadata": {
        "id": "0bYhCU3Ul_fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save to csv file"
      ],
      "metadata": {
        "id": "ieE9iSTsmLvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save daily aggregated news embedding into csv file\n",
        "\n",
        "aggregated_bbri_embeddings.to_csv(\"bbri_embedding_daily_full.csv\", index=False)\n",
        "aggregated_bbca_embeddings.to_csv(\"bbca_embedding_daily_full.csv\", index=False)\n",
        "aggregated_bmri_embeddings.to_csv(\"bmri_embedding_daily_full.csv\", index=False)"
      ],
      "metadata": {
        "id": "c0p8oEuomNFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}