{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNHshyYlqzGj"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notebook contain the process of finding the best configuration and learning rate for the GRU model that is used as one the base learner in this study. The dataset that is used is the selected feature from financial statements (based on the feature selection result) and also the best sentiment representation from the sentiment experiment result. The dataset that is used is the BBRI dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAH87mrbyBB-"
      },
      "source": [
        "# Base Model Search for Stock Prediction using fundamental and embedding sentiment feature (GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WH7JjYlyZtv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# DEFINE CONSTANT\n",
        "TRAIN_SIZE = 0.70\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15\n",
        "\n",
        "# EXPERIMENT VARIABLE\n",
        "# used learning rate -> 0.001, 0.005, 0.0001, 0.0005\n",
        "LEARNING_RATE = 0.05\n",
        "\n",
        "N_ITERATION = 20\n",
        "N_COMPONENT_PCA = 0.80\n",
        "TARGET_COLUMN_NAME = \"Closing Price\"\n",
        "EMBEDDING_COLUMN_NAME = \"text_embedding_multilingual_mpnet\"\n",
        "USE_PCA = True\n",
        "\n",
        "CONTEXT_WINDOW = 5\n",
        "NUM_EPOCHS = 100\n",
        "LOSS = \"mse\"\n",
        "METRICS = \"mape\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFI1K8sb1-_F",
        "outputId": "b86c19a7-8b47-426e-c40e-ca2199c41435"
      },
      "outputs": [],
      "source": [
        "fundamental_features  = [\n",
        "  \"Financing Cash Flow\",\n",
        "  \"P/B Ratio\",\n",
        "  \"P/S Ratio\",\n",
        "  \"Capital Adequacy Ratio\",\n",
        "  \"Debt to Assets Ratio\",\n",
        "  \"Debt to Equity Ratio\",\n",
        "  \"Investing Cash Flow\",\n",
        "  \"Operating Cash Flow\",\n",
        "  \"Return on Assets\",\n",
        "  \"Operating Profit\",\n",
        "  \"Loan to Deposit Ratio\"\n",
        "]\n",
        "\n",
        "historic_price_feature = [\n",
        "    'Opening Price',\n",
        "    'Highest Price',\n",
        "    'Lowest Price',\n",
        "    'Volume',\n",
        "    'Change'\n",
        "]\n",
        "\n",
        "print(f\"Number of selected features: {len(fundamental_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRz3lb0ty7V7"
      },
      "outputs": [],
      "source": [
        "def parse_embedding_from_df(df, embedding_column_name, n_comp, target_column_name=\"Closing Price\"):\n",
        "\n",
        "  feature_columns = fundamental_features + historic_price_feature\n",
        "\n",
        "  column = [target_column_name, embedding_column_name] + feature_columns\n",
        "  df_processed = df[column].copy()\n",
        "\n",
        "  def parse_embedding_string(embedding_str):\n",
        "\n",
        "      if not isinstance(embedding_str, str):\n",
        "          return None # Handle non-string inputs (like NaN)\n",
        "\n",
        "      # Remove brackets and split by whitespace\n",
        "      embedding_str = embedding_str.strip().strip('[]')\n",
        "      # Use regex to find all floating point numbers, including those in scientific notation\n",
        "      numbers = re.findall(r\"[-+]?\\d*\\.?\\d+[eE][-+]?\\d+|[-+]?\\d*\\.\\d+|\\d+\", embedding_str)\n",
        "\n",
        "      try:\n",
        "          # Convert the extracted numbers to floats\n",
        "          return [float(num) for num in numbers]\n",
        "      except ValueError:\n",
        "          return None # Return None if conversion to float fails for any number\n",
        "\n",
        "  # Apply the parsing function to the embedding column and handle potential None values\n",
        "  df_processed['embedding'] = df_processed[embedding_column_name].apply(parse_embedding_string)\n",
        "\n",
        "  # Handle rows where parsing failed (e.g., by filling with zeros)\n",
        "  # Determine the embedding dimension from the first successfully parsed embedding\n",
        "  embedding_dim = None\n",
        "  for embedding_list in df_processed['embedding']:\n",
        "      if embedding_list is not None:\n",
        "          embedding_dim = len(embedding_list)\n",
        "          break\n",
        "\n",
        "  if embedding_dim is None:\n",
        "      # Handle case where all embeddings are None or invalid\n",
        "      # Using a default BERT base dimension as a fallback.\n",
        "      embedding_dim = 768 # Default BERT base dimension\n",
        "      print(f\"Warning: Could not determine embedding dimension from data. Using a default embedding dimension of {embedding_dim}.\")\n",
        "\n",
        "  df_processed['embedding'] = df_processed['embedding'].apply(lambda x: np.array(x, dtype=float) if x is not None else np.zeros(embedding_dim))\n",
        "\n",
        "  def pca_reduce(embedding_list, n_comp=n_comp):\n",
        "    pca = PCA(n_components=n_comp)\n",
        "    embedding_reduced = pca.fit_transform(np.array(embedding_list.tolist())) # Convert list of arrays to numpy array\n",
        "    return embedding_reduced\n",
        "\n",
        "  df_processed['embedding_pca'] = pca_reduce(df_processed['embedding']).tolist()\n",
        "\n",
        "  # Convert feature columns to numeric, coercing errors, and fill NaNs\n",
        "  for col in feature_columns:\n",
        "      df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
        "\n",
        "  return df_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcrgRHIY0Bfo"
      },
      "outputs": [],
      "source": [
        "def create_train_val_test(df_processed, use_pca, embedding_column_name, target_column_price=\"Closing Price\"):\n",
        "\n",
        "    # Separate target variable and features\n",
        "    target_data = df_processed[target_column_price].values\n",
        "\n",
        "    # Exclude the original embedding column and 'Date' from feature_columns\n",
        "    feature_columns = [col for col in df_processed.columns if col not in [target_column_price, embedding_column_name, 'Date', 'embedding', 'embedding_pca']]\n",
        "    feature_data = df_processed[feature_columns].values\n",
        "\n",
        "    if use_pca:\n",
        "      embedding_data = np.array(df_processed['embedding_pca'].tolist())\n",
        "    else:\n",
        "      embedding_data = np.array(df_processed['embedding'].tolist())\n",
        "\n",
        "    # Scale the target variable\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_target_data = scaler.fit_transform(target_data.reshape(-1, 1))\n",
        "\n",
        "    # Scale the feature data (excluding embedding)\n",
        "    feature_scaler = MinMaxScaler()\n",
        "\n",
        "    scaled_feature_data = feature_scaler.fit_transform(feature_data)\n",
        "\n",
        "    # Combine scaled target, scaled features, and original embeddings\n",
        "    # Target variable 'close' is at index 0\n",
        "    combined_data = np.concatenate((scaled_target_data, embedding_data, scaled_feature_data), axis=1)\n",
        "\n",
        "    # Calculate split indices\n",
        "    n_total = len(combined_data) - CONTEXT_WINDOW\n",
        "    train_split_index = int(n_total * TRAIN_SIZE)\n",
        "    val_split_index = int(n_total * (TRAIN_SIZE + VAL_SIZE))\n",
        "\n",
        "    # Split the data sequentially\n",
        "    train_data = combined_data[:train_split_index + CONTEXT_WINDOW]\n",
        "    val_data = combined_data[train_split_index:val_split_index + CONTEXT_WINDOW]\n",
        "    test_data = combined_data[val_split_index:]\n",
        "\n",
        "    train_generator = TimeseriesGenerator(train_data, train_data[:, 0], # Target is the first column (scaled 'close')\n",
        "                                        length=CONTEXT_WINDOW, batch_size=24)\n",
        "\n",
        "    val_generator = TimeseriesGenerator(val_data, val_data[:, 0], # Target is the first column (scaled 'close')\n",
        "                                        length=CONTEXT_WINDOW, batch_size=24)\n",
        "\n",
        "    test_generator = TimeseriesGenerator(test_data, test_data[:, 0], # Target is the first column (scaled 'close')\n",
        "                                      length=CONTEXT_WINDOW, batch_size=24)\n",
        "\n",
        "    return train_generator, val_generator, test_generator, scaler, combined_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-h67nrr629N"
      },
      "source": [
        "## GRU with Configuration 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH3e1kBkxECr"
      },
      "outputs": [],
      "source": [
        "def create_model_gru_1(combined_data, print_summary=True):\n",
        "\n",
        "  model = Sequential([\n",
        "      Input(shape=(CONTEXT_WINDOW, combined_data.shape[1])),\n",
        "      GRU(64, activation='relu'),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1, activation='linear')\n",
        "  ])\n",
        "\n",
        "  OPTIMIZER = Adam(learning_rate=LEARNING_RATE)\n",
        "  model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[METRICS])\n",
        "\n",
        "  if print_summary:\n",
        "    model.summary()\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azd4lw32xF8v"
      },
      "source": [
        "## GRU with Configuration 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVnoHmPf67wJ"
      },
      "outputs": [],
      "source": [
        "def create_model_gru_2(combined_data, print_summary=True):\n",
        "\n",
        "  model = Sequential([\n",
        "      Input(shape=(CONTEXT_WINDOW, combined_data.shape[1])),\n",
        "      GRU(units=64,\n",
        "          activation='relu',\n",
        "          return_sequences=True,\n",
        "          kernel_regularizer=L2(0.001)\n",
        "      ),\n",
        "      GRU(units=32,\n",
        "          activation='relu',\n",
        "          recurrent_dropout=0.25\n",
        "      ),\n",
        "      Dropout(0.25),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1, activation='linear')\n",
        "  ])\n",
        "\n",
        "  OPTIMIZER = Adam(learning_rate=LEARNING_RATE)\n",
        "  model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[METRICS])\n",
        "\n",
        "  if print_summary:\n",
        "    model.summary()\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIDElOumIK9y"
      },
      "source": [
        "## GRU with Configuration 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EojekdsnIKWS"
      },
      "outputs": [],
      "source": [
        "def create_model_gru_3(combined_data, print_summary=True):\n",
        "\n",
        "  model = Sequential([\n",
        "      Input(shape=(CONTEXT_WINDOW, combined_data.shape[1])),\n",
        "      GRU(units=64,\n",
        "          activation='relu',\n",
        "          return_sequences=True,\n",
        "          kernel_regularizer=L2(0.001)\n",
        "      ),\n",
        "      GRU(units=32,\n",
        "          activation='relu',\n",
        "          recurrent_dropout=0.25\n",
        "      ),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1, activation='linear')\n",
        "  ])\n",
        "\n",
        "  OPTIMIZER = Adam(learning_rate=LEARNING_RATE)\n",
        "  model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[METRICS])\n",
        "\n",
        "  if print_summary:\n",
        "    model.summary()\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65GiEZlu0Y8n"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_visualize_model(model, train_generator, val_generator, test_generator, scaler, embedding_column_name, print_test_result=False, visualize=True):\n",
        "\n",
        "  # Define Early Stopping callback\n",
        "  early_stopping = EarlyStopping(\n",
        "      monitor='val_loss', # Monitor validation loss\n",
        "      patience=10,        # Number of epochs with no improvement after which training will be stopped.\n",
        "      restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity.\n",
        "  )\n",
        "\n",
        "  # Train the model with Early Stopping\n",
        "  history = model.fit(\n",
        "      train_generator,\n",
        "      validation_data=val_generator,\n",
        "      epochs=NUM_EPOCHS,\n",
        "      verbose=0,\n",
        "      callbacks=[early_stopping] # Add the early stopping callback here\n",
        "  )\n",
        "\n",
        "  # Get predictions from the test set\n",
        "  predictions_scaled = model.predict(test_generator, verbose=0)\n",
        "\n",
        "  # Inverse transform the scaled predictions and actual values to their original scale\n",
        "  predicted_actual = scaler.inverse_transform(predictions_scaled)\n",
        "  true_actual = scaler.inverse_transform(test_generator.targets.reshape(-1, 1))\n",
        "\n",
        "  # Adjust the length of true_actual to match predicted_actual\n",
        "  true_actual = true_actual[:len(predicted_actual)]\n",
        "\n",
        "  # Calculate evaluation metrics\n",
        "  mse = mean_squared_error(true_actual, predicted_actual)\n",
        "  mae = mean_absolute_error(true_actual, predicted_actual)\n",
        "  mape = mean_absolute_percentage_error(true_actual, predicted_actual)\n",
        "\n",
        "  if print_test_result:\n",
        "    print(\"TEST RESULT\")\n",
        "    print(f\"Test MSE: {mse:.3f}\")\n",
        "    print(f\"Test MAE: {mae:.3f}\")\n",
        "    print(f\"Test MAPE: {(mape*100):.2f}%\")\n",
        "\n",
        "  if visualize:\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(true_actual, label='Actual close')\n",
        "    plt.plot(predicted_actual, label=f'Predicted close with ({embedding_column_name})')\n",
        "\n",
        "    # Add dots for each data point\n",
        "    plt.scatter(range(len(true_actual)), true_actual, color='darkblue', s=12, label='Actual Points')\n",
        "    plt.scatter(range(len(predicted_actual)), predicted_actual, color='red', s=12, label='Predicted Points')\n",
        "\n",
        "    plt.title(f'{embedding_column_name} Predictions vs Actual Close Price')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Set x-axis major locator to 10\n",
        "    plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  return mse, mae, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzB62rf80nOQ"
      },
      "outputs": [],
      "source": [
        "def find_average_test_score(df, embedding_name, use_pca, n_iter, model_number):\n",
        "  processed_df = parse_embedding_from_df(df, embedding_name, n_comp=N_COMPONENT_PCA)\n",
        "  train_generator, val_generator, test_generator, scaler, combined_data = create_train_val_test(processed_df, use_pca, embedding_name)\n",
        "  arr_mse = []\n",
        "  arr_mae = []\n",
        "  arr_mape = []\n",
        "\n",
        "  for i in tqdm(range(n_iter), desc=f\"Processing Model Number {model_number}\"):\n",
        "    if model_number == 1:\n",
        "      model = create_model_gru_1(combined_data, print_summary=False)\n",
        "    elif model_number == 2:\n",
        "      model = create_model_gru_2(combined_data, print_summary=False)\n",
        "    elif model_number == 3:\n",
        "      model = create_model_gru_3(combined_data, print_summary=False)\n",
        "\n",
        "    mse, mae, mape = evaluate_and_visualize_model(model, train_generator, val_generator, test_generator, scaler, embedding_name, print_test_result=False, visualize=False)\n",
        "    arr_mse.append(mse)\n",
        "    arr_mae.append(mae)\n",
        "    arr_mape.append(mape)\n",
        "\n",
        "  print(\"\\n\\n\")\n",
        "  print(\"Final Result:\")\n",
        "  print(f\"Average MSE: {np.mean(arr_mse):.3f}\")\n",
        "  print(f\"Average MAE: {np.mean(arr_mae):.3f}\")\n",
        "  print(f\"Average MAPE: {(np.mean(arr_mape)*100):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S4mkU96453a"
      },
      "outputs": [],
      "source": [
        "bbri_merged_df = pd.read_csv(\"final_bbri_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Om4A8Ldtac"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aO6r8mI0EPg"
      },
      "outputs": [],
      "source": [
        "# Prediction using model_conf = 1\n",
        "MODEL_NUMBER_GRU_SIMPLE = 1\n",
        "\n",
        "find_average_test_score(\n",
        "    df=bbri_merged_df,\n",
        "    embedding_name=EMBEDDING_COLUMN_NAME,\n",
        "    use_pca=USE_PCA,\n",
        "    n_iter=N_ITERATION,\n",
        "    model_number=MODEL_NUMBER_GRU_SIMPLE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB-xOdfw0FUZ"
      },
      "outputs": [],
      "source": [
        "# Prediction using model_conf = 2\n",
        "MODEL_NUMBER_GRU_COMPLICATED = 2\n",
        "\n",
        "find_average_test_score(\n",
        "    df=bbri_merged_df,\n",
        "    embedding_name=EMBEDDING_COLUMN_NAME,\n",
        "    use_pca=USE_PCA,\n",
        "    n_iter=N_ITERATION,\n",
        "    model_number=MODEL_NUMBER_GRU_COMPLICATED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "21d8ed71600840ae8e2fb9fbe4a5cd73",
            "14687e78876e4179823c0d2df5841d09",
            "1462155f97134847a40ac3402366cc60",
            "71db873c7c804ad98dacef5fd71f0ac6",
            "5f690d794edb42239711074b2a47128d",
            "1330798256324f02be593cbfdf44a880",
            "7d13ed0dc6c04f95beae3c583c0d76fb",
            "4a712c333a8142279c2fa937dfb62682",
            "264aa1c7b2b34523862635c02af09771",
            "754055395f6b48a79911b7e0f14c8175",
            "313564e5db3e4ba081338403d2422f85"
          ]
        },
        "id": "6Q-mMMQ-PXDg",
        "outputId": "ca2ee104-76eb-4973-9f40-4e75d6608086"
      },
      "outputs": [],
      "source": [
        "# Prediction using model_conf = 3\n",
        "MODEL_NUMBER_GRU_SPECIAL = 3\n",
        "\n",
        "find_average_test_score(\n",
        "    df=bbri_merged_df,\n",
        "    embedding_name=EMBEDDING_COLUMN_NAME,\n",
        "    use_pca=USE_PCA,\n",
        "    n_iter=N_ITERATION,\n",
        "    model_number=MODEL_NUMBER_GRU_SPECIAL\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1330798256324f02be593cbfdf44a880": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1462155f97134847a40ac3402366cc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a712c333a8142279c2fa937dfb62682",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_264aa1c7b2b34523862635c02af09771",
            "value": 20
          }
        },
        "14687e78876e4179823c0d2df5841d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1330798256324f02be593cbfdf44a880",
            "placeholder": "​",
            "style": "IPY_MODEL_7d13ed0dc6c04f95beae3c583c0d76fb",
            "value": "Processing Model Number 3: 100%"
          }
        },
        "21d8ed71600840ae8e2fb9fbe4a5cd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14687e78876e4179823c0d2df5841d09",
              "IPY_MODEL_1462155f97134847a40ac3402366cc60",
              "IPY_MODEL_71db873c7c804ad98dacef5fd71f0ac6"
            ],
            "layout": "IPY_MODEL_5f690d794edb42239711074b2a47128d"
          }
        },
        "264aa1c7b2b34523862635c02af09771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "313564e5db3e4ba081338403d2422f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a712c333a8142279c2fa937dfb62682": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f690d794edb42239711074b2a47128d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71db873c7c804ad98dacef5fd71f0ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754055395f6b48a79911b7e0f14c8175",
            "placeholder": "​",
            "style": "IPY_MODEL_313564e5db3e4ba081338403d2422f85",
            "value": " 20/20 [11:48&lt;00:00, 45.24s/it]"
          }
        },
        "754055395f6b48a79911b7e0f14c8175": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d13ed0dc6c04f95beae3c583c0d76fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
